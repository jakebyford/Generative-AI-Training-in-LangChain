{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db1c786",
   "metadata": {},
   "source": [
    "# ðŸ”— What Are Chains in LangChain?\n",
    "\n",
    "## **ðŸ“Œ Definition**\n",
    "In LangChain, a **chain** is a **sequence of steps** (like prompt templates, LLMs, tools, or functions) that are **connected together** to form a complete **AI workflow**.\n",
    "\n",
    "Think of a chain as a **pipeline** that takes an input, processes it through multiple steps, and produces a final output.\n",
    "\n",
    "---\n",
    "\n",
    "## **ðŸ”¹ Why Use Chains?**\n",
    "Chains let you:\n",
    "- âœ… Combine multiple operations (e.g. prompt â†’ LLM â†’ output parsing)\n",
    "- âœ… Reuse and modularize logic\n",
    "- âœ… Build powerful workflows like **question answering, summarization, RAG, chatbots**, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## **ðŸ”¹ Common Use Cases for Chains**\n",
    "| **Use Case** | **Example** |\n",
    "|--------------|-------------|\n",
    "| Summarization | Input text â†’ Prompt â†’ LLM â†’ Summary |\n",
    "| Q&A over documents | Question â†’ Embed â†’ Search â†’ Prompt â†’ LLM |\n",
    "| Chatbot | User input â†’ Memory â†’ Prompt â†’ LLM â†’ Response |\n",
    "| Data enrichment | Product name â†’ Prompt â†’ LLM â†’ Tags, description, etc. |\n",
    "\n",
    "---\n",
    "\n",
    "## **ðŸ”¹ Chain = Steps Connected Together**\n",
    "```text\n",
    "Input â†’ [Prompt Template] â†’ [Custom Runnbale] â†’ [LLM] â†’ [Parser] â†’ Output\n",
    "```\n",
    "`chain = prompt | RunnableLambda | llm | parser`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8dc73",
   "metadata": {},
   "source": [
    "# âš™ï¸ What Are Runnables in LangChain?\n",
    "\n",
    "## ðŸ“Œ Definition\n",
    "**Runnables** are the **core building blocks** of LangChain's modern **LCEL (LangChain Expression Language)**.\n",
    "\n",
    "A **Runnable** is an object that:\n",
    "- Can be **invoked** with an input (`.invoke()`).\n",
    "- Can be **chained** using the `|` operator.\n",
    "- Can be **composed** to build flexible and powerful AI workflows.\n",
    "\n",
    "Many LangChain components, including `LLMs`, `output parsers`, `retrievers`, and `prompt templates`, implement the Runnable interface. \n",
    " \n",
    "---\n",
    "\n",
    "## ðŸ”— Why Use Runnables?\n",
    "\n",
    "| âœ… Feature | ðŸ“– Description |\n",
    "|-----------|----------------|\n",
    "| **Composable** | Combine steps like prompts, models, tools, and functions |\n",
    "| **Modular** | Build reusable and testable components |\n",
    "| **Flexible** | Add branching, parallelism, retry logic, validation, etc. |\n",
    "| **Fast & Declarative** | Easier to read and debug than old-style chains |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© Types of Runnables\n",
    "\n",
    "| **Runnable Type** | **Purpose** |\n",
    "|-------------------|-------------|\n",
    "| `RunnableLambda` | Wraps a Python function |\n",
    "| `RunnableSequence` | Runs steps in sequence |\n",
    "| `RunnableParallel` | Runs multiple steps in parallel |\n",
    "| `RunnablePassthrough` | Forwards input unchanged |\n",
    "| `.assign()` | Adds computed fields |\n",
    "| `.bind()` | Binds constant arguments |\n",
    "| `.with_retry()` | Adds retry logic |\n",
    "| `.with_types()` | Adds input/output validation |\n",
    "|`.get_graph()` | Visualize chain structure |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dca4947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read api_key from file\n",
    "with open('../api_keys.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "    # print(api_key)\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba9cdab6-7337-42ee-9299-9bd98b6105fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda465bc-5863-4393-a67d-97352a32b1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['product'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['product'], template='Make up a funny company name for a company that produces {product}'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promt_from_template = ChatPromptTemplate.from_template(\"Make up a funny company name for a company that produces {product}\")\n",
    "promt_from_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e3476",
   "metadata": {},
   "source": [
    "### â˜•ï¸ Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21395065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['product'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['product'], template='Make up a funny company name for a company that produces {product}'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_from_messages = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"Make up a funny company name for a company that produces {product}\")\n",
    "])\n",
    "\n",
    "prompt_from_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8278652-4c42-4ef1-a32b-6e971cccf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94bc9642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Byte Me Computers'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use promt_from_template\n",
    "chain = prompt_from_messages | llm | StrOutputParser() \n",
    " \n",
    "chain.invoke({\"product\": \"Computers\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc77961",
   "metadata": {},
   "source": [
    "## ðŸ“Œ **L**ang**C**hain **E**xpression **L**anguage (LCEL)\n",
    "\n",
    "**LCEL (LangChain Expression Language)** is a new, powerful way to build AI workflows in LangChain using **composable Runnables**.  \n",
    "It replaces the older `Chain`-based APIs with a more **modular, flexible, and readable syntax**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Key Concepts\n",
    "\n",
    "| **Feature** | **Description** |\n",
    "|-------------|-----------------|\n",
    "| **Composable** | Chain together steps using the `|` operator |\n",
    "| **Modular** | Each step is a `Runnable` (LLM, prompt, parser, logic, etc.) |\n",
    "| **Declarative** | Define pipelines in a readable, function-like style |\n",
    "| **Extensible** | Add custom logic, parallelism, retries, type validation |\n",
    "\n",
    "---\n",
    "\n",
    "- https://python.langchain.com/docs/concepts/lcel/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2e187",
   "metadata": {},
   "source": [
    "## **LCEL Syntax**\n",
    "To understand LCEL syntax let's first build a simple chain in typical Python syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef78c0",
   "metadata": {},
   "source": [
    "### Using LCEL the format is different, rather than relying on Chains we simple chain together each component using the pipe operator `|`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6770d26",
   "metadata": {},
   "source": [
    "### Let's break it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03795f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Make up a funny company name for a company that produces Computers')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = prompt_from_messages.invoke({\"product\": \"Computers\"})\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fa427b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Byte Me Computing Co.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 19, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9ee6064d-9294-4ae3-a051-49bab73809cd-0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(chat_prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d2c7812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Byte Me Computing Co.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StrOutputParser().invoke(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a6d27",
   "metadata": {},
   "source": [
    "## **How the Pipe (`|`) Operator Works**\n",
    "### **ðŸ”¹ Bitwise OR (`|`) for Integers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "463e428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(21 | 22) > 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "605a9476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(21 | 22) > 21.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf340a-9054-4ede-a945-500250c4b7e1",
   "metadata": {},
   "source": [
    "## **In Langchain**\n",
    "To really understand LCEL we can take a look at how this pipe operation works. We know it takes output from the right and feeds it to the left â€” but this isn't typical Python, so how is this implemented? Let's try creating our own version of this with some simple functions.\n",
    "\n",
    "We will be using the `__or__` method within Python class objects. When we place two classes together like c`hain = class_a | class_b` the Python interpreter will check if these classes contain this `__or__` method. If they do then our `|` code will be translated into `chain = class_a.__or__(class_b)`.\n",
    "\n",
    "That means both of these patterns will return the same thing:\n",
    "\n",
    "```python\n",
    "# object approach\n",
    "chain = class_a.__or__(class_b)\n",
    "chain(\"some input\")\n",
    "\n",
    "# pipe approach\n",
    "chain = class_a | class_b\n",
    "chain(\"some input\")\n",
    "```\n",
    "\n",
    "With that in mind, we can build a `Runnable` class that consumes a function and turns it into a function that can be chained with other functions using the pipe operator `|`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035ed25",
   "metadata": {},
   "source": [
    "```Python\n",
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.execute = func  # Store the function\n",
    "\n",
    "    def __or__(self, next_runnable): # other is a Runnable object\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # Ensure the result from self.func is passed to other.func correctly\n",
    "            return next_runnable.execute(self.execute(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "    \n",
    "\n",
    "    def invoke(self, *args, **kwargs):  # Ensure invoke method exists\n",
    "        return self.execute(*args, **kwargs)\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e368550",
   "metadata": {},
   "source": [
    "## ðŸ§± Breaking Down the Custom `Runnable` Class in Python\n",
    "\n",
    "### **1. Constructor (`__init__` Method)**\n",
    "\n",
    "```Python\n",
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.execute = func\n",
    "```\n",
    "\n",
    "- Takes a function `(func)` as an argument.\n",
    "- Stores this function inside the instance (`self.execute`).\n",
    "- This allows Runnable to wrap any function and call it later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d608b6",
   "metadata": {},
   "source": [
    "### **2. Overloading the `|` (Pipe) Operator**\n",
    "\n",
    "```python\n",
    "def __or__(self, next_runnable):\n",
    "```\n",
    "\n",
    "- This overloads the `|` operator, allowing chaining (`Runnable | Runnable`).\n",
    "- When used (`A | B`), `B` is applied to the result of `A`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb45829",
   "metadata": {},
   "source": [
    "```python\n",
    "def chained_func(*args, **kwargs):\n",
    "```\n",
    "- Defines `chained_func`, which wraps the two functions being chained.\n",
    "- `*args, **kwargs` allow passing any number of arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78353f8",
   "metadata": {},
   "source": [
    "```python\n",
    "return next_runnable.execute(self.execute(*args, **kwargs))\n",
    "```\n",
    "\n",
    "- Calls `self.execute` (the first function in the chain).\n",
    "- Passes its output as input to `next_runnable.execute` (the next function in the chain).\n",
    "- Executes `next_runnable` immediately with the result from `self.execute`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837e513",
   "metadata": {},
   "source": [
    "```python\n",
    "return Runnable(chained_func)\n",
    "```\n",
    "- Returns a new `Runnable` instance containing `chained_func`, enabling further chaining.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fd480",
   "metadata": {},
   "source": [
    "### **3. Calling the Function (`invoke` Method)**\n",
    "\n",
    "```python\n",
    "def invoke(self, *args, **kwargs):  # Ensure invoke method exists\n",
    "        return self.func(*args, **kwargs)\n",
    "\n",
    "```\n",
    "- Defines `invoke`, allowing instances of `Runnable` to be called like functions.\n",
    "- When called, it executes the wrapped function (`self.func`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0113b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.execute = func  # Store the function\n",
    "\n",
    "\n",
    "    def __or__(self, next_runnable): # other is a Runnable object\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # Ensure the result from self.func is passed to other.func correctly\n",
    "            return next_runnable.execute(self.execute(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "\n",
    "\n",
    "    def invoke(self, *args, **kwargs):  # Ensure invoke method exists\n",
    "        return self.execute(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2603882",
   "metadata": {},
   "source": [
    "## ðŸ‘€ Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94220f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions\n",
    "def add_five(x):\n",
    "    return x + 5\n",
    "\n",
    "\n",
    "def multiply_by_two(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Wrap the functions with Runnable\n",
    "add_five_runnable = Runnable(add_five)\n",
    "multiply_by_two_runnable = Runnable(multiply_by_two)\n",
    "\n",
    "\n",
    "# Chain the functions\n",
    "chain = add_five_runnable.__or__(multiply_by_two_runnable)  # First add 5, then multiply by 2\n",
    "\n",
    "\n",
    "# Invoke the chain\n",
    "chain.invoke(3)\n",
    "# Output: (3 + 5) * 2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352bfc0",
   "metadata": {},
   "source": [
    "### Using `__or__` directly we get the correct answer, now let's try using the pipe operator `|` to chain them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1f2872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain the runnable functions together\n",
    "chain = add_five_runnable | multiply_by_two_runnable\n",
    "\n",
    "# invoke the chain\n",
    "chain.invoke(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
