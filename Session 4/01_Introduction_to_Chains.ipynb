{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db1c786",
   "metadata": {},
   "source": [
    "# üîó What Are Chains in LangChain?\n",
    "\n",
    "## **üìå Definition**\n",
    "In LangChain, a **chain** is a **sequence of steps** (like prompt templates, LLMs, tools, or functions) that are **connected together** to form a complete **AI workflow**.\n",
    "\n",
    "Think of a chain as a **pipeline** that takes an input, processes it through multiple steps, and produces a final output.\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Why Use Chains?**\n",
    "Chains let you:\n",
    "- ‚úÖ Combine multiple operations (e.g. prompt ‚Üí LLM ‚Üí output parsing)\n",
    "- ‚úÖ Reuse and modularize logic\n",
    "- ‚úÖ Build powerful workflows like **question answering, summarization, RAG, chatbots**, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Common Use Cases for Chains**\n",
    "| **Use Case** | **Example** |\n",
    "|--------------|-------------|\n",
    "| Summarization | Input text ‚Üí Prompt ‚Üí LLM ‚Üí Summary |\n",
    "| Q&A over documents | Question ‚Üí Embed ‚Üí Search ‚Üí Prompt ‚Üí LLM |\n",
    "| Chatbot | User input ‚Üí Memory ‚Üí Prompt ‚Üí LLM ‚Üí Response |\n",
    "| Data enrichment | Product name ‚Üí Prompt ‚Üí LLM ‚Üí Tags, description, etc. |\n",
    "\n",
    "---\n",
    "\n",
    "## **üîπ Chain = Steps Connected Together**\n",
    "```text\n",
    "Input ‚Üí [Prompt Template] ‚Üí [Custom Runnbale] ‚Üí [LLM] ‚Üí [Parser] ‚Üí Output\n",
    "```\n",
    "`chain = prompt | RunnableLambda | llm | parser`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8dc73",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è What Are Runnables in LangChain?\n",
    "\n",
    "## üìå Definition\n",
    "**Runnables** are the **core building blocks** of LangChain's modern **LCEL (LangChain Expression Language)**.\n",
    "\n",
    "A **Runnable** is an object that:\n",
    "- Can be **invoked** with an input (`.invoke()`).\n",
    "- Can be **chained** using the `|` operator.\n",
    "- Can be **composed** to build flexible and powerful AI workflows.\n",
    "\n",
    "Many LangChain components, including `LLMs`, `output parsers`, `retrievers`, and `prompt templates`, implement the Runnable interface. \n",
    " \n",
    "---\n",
    "\n",
    "## üîó Why Use Runnables?\n",
    "\n",
    "| ‚úÖ Feature | üìñ Description |\n",
    "|-----------|----------------|\n",
    "| **Composable** | Combine steps like prompts, models, tools, and functions |\n",
    "| **Modular** | Build reusable and testable components |\n",
    "| **Flexible** | Add branching, parallelism, retry logic, validation, etc. |\n",
    "| **Fast & Declarative** | Easier to read and debug than old-style chains |\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Types of Runnables\n",
    "\n",
    "| **Runnable Type** | **Purpose** |\n",
    "|-------------------|-------------|\n",
    "| `RunnableLambda` | Wraps a Python function |\n",
    "| `RunnableSequence` | Runs steps in sequence |\n",
    "| `RunnableParallel` | Runs multiple steps in parallel |\n",
    "| `RunnablePassthrough` | Forwards input unchanged |\n",
    "| `.assign()` | Adds computed fields |\n",
    "| `.bind()` | Binds constant arguments |\n",
    "| `.with_retry()` | Adds retry logic |\n",
    "| `.with_types()` | Adds input/output validation |\n",
    "|`.get_graph()` | Visualize chain structure |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dca4947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read api_key from file\n",
    "with open('../api_keys.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "    # print(api_key)\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba9cdab6-7337-42ee-9299-9bd98b6105fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda465bc-5863-4393-a67d-97352a32b1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['product'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['product'], template='Make up a funny company name for a company that produces {product}'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promt_from_template = ChatPromptTemplate.from_template(\"Make up a funny company name for a company that produces {product}\")\n",
    "promt_from_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e3476",
   "metadata": {},
   "source": [
    "### ‚òïÔ∏è Or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21395065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['product'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['product'], template='Make up a funny company name for a company that produces {product}'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_from_messages = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"Make up a funny company name for a company that produces {product}\")\n",
    "])\n",
    "\n",
    "prompt_from_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8278652-4c42-4ef1-a32b-6e971cccf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94bc9642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Byte Me Computers'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use promt_from_template\n",
    "chain = prompt_from_messages | llm | StrOutputParser() \n",
    " \n",
    "chain.invoke({\"product\": \"Computers\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc77961",
   "metadata": {},
   "source": [
    "## üìå **L**ang**C**hain **E**xpression **L**anguage (LCEL)\n",
    "\n",
    "**LCEL (LangChain Expression Language)** is a new, powerful way to build AI workflows in LangChain using **composable Runnables**.  \n",
    "It replaces the older `Chain`-based APIs with a more **modular, flexible, and readable syntax**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Key Concepts\n",
    "\n",
    "| **Feature** | **Description** |\n",
    "|-------------|-----------------|\n",
    "| **Composable** | Chain together steps using the `|` operator |\n",
    "| **Modular** | Each step is a `Runnable` (LLM, prompt, parser, logic, etc.) |\n",
    "| **Declarative** | Define pipelines in a readable, function-like style |\n",
    "| **Extensible** | Add custom logic, parallelism, retries, type validation |\n",
    "\n",
    "---\n",
    "\n",
    "- https://python.langchain.com/docs/concepts/lcel/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d2e187",
   "metadata": {},
   "source": [
    "## **LCEL Syntax**\n",
    "To understand LCEL syntax let's first build a simple chain in typical Python syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef78c0",
   "metadata": {},
   "source": [
    "### Using LCEL the format is different, rather than relying on Chains we simple chain together each component using the pipe operator `|`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6770d26",
   "metadata": {},
   "source": [
    "### Let's break it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03795f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Make up a funny company name for a company that produces Computers')])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = prompt_from_messages.invoke({\"product\": \"Computers\"})\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fa427b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Byte Me Computing Co.', response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 19, 'total_tokens': 25, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9ee6064d-9294-4ae3-a051-49bab73809cd-0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(chat_prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d2c7812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Byte Me Computing Co.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StrOutputParser().invoke(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917a6d27",
   "metadata": {},
   "source": [
    "## **How the Pipe (`|`) Operator Works**\n",
    "### **üîπ Bitwise OR (`|`) for Integers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "463e428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(21 | 22) > 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "605a9476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(21 | 22) > 21.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf340a-9054-4ede-a945-500250c4b7e1",
   "metadata": {},
   "source": [
    "## **In Langchain**\n",
    "To really understand LCEL we can take a look at how this pipe operation works. We know it takes output from the right and feeds it to the left ‚Äî but this isn't typical Python, so how is this implemented? Let's try creating our own version of this with some simple functions.\n",
    "\n",
    "We will be using the `__or__` method within Python class objects. When we place two classes together like c`hain = class_a | class_b` the Python interpreter will check if these classes contain this `__or__` method. If they do then our `|` code will be translated into `chain = class_a.__or__(class_b)`.\n",
    "\n",
    "That means both of these patterns will return the same thing:\n",
    "\n",
    "```python\n",
    "# object approach\n",
    "chain = class_a.__or__(class_b)\n",
    "chain(\"some input\")\n",
    "\n",
    "# pipe approach\n",
    "chain = class_a | class_b\n",
    "chain(\"some input\")\n",
    "```\n",
    "\n",
    "With that in mind, we can build a `Runnable` class that consumes a function and turns it into a function that can be chained with other functions using the pipe operator `|`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035ed25",
   "metadata": {},
   "source": [
    "```Python\n",
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.execute = func  # Store the function\n",
    "\n",
    "    def __or__(self, next_runnable): # other is a Runnable object\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # Ensure the result from self.func is passed to other.func correctly\n",
    "            return next_runnable.execute(self.execute(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "    \n",
    "\n",
    "    def invoke(self, *args, **kwargs):  # Ensure invoke method exists\n",
    "        return self.execute(*args, **kwargs)\n",
    "```\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e368550",
   "metadata": {},
   "source": [
    "## üß± Breaking Down the Custom `Runnable` Class in Python\n",
    "\n",
    "### **1. Constructor (`__init__` Method)**\n",
    "\n",
    "```Python\n",
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.execute = func\n",
    "```\n",
    "\n",
    "- Takes a function `(func)` as an argument.\n",
    "- Stores this function inside the instance (`self.execute`).\n",
    "- This allows Runnable to wrap any function and call it later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d608b6",
   "metadata": {},
   "source": [
    "### **2. Overloading the `|` (Pipe) Operator**\n",
    "\n",
    "```python\n",
    "def __or__(self, next_runnable):\n",
    "```\n",
    "\n",
    "- This overloads the `|` operator, allowing chaining (`Runnable | Runnable`).\n",
    "- When used (`A | B`), `B` is applied to the result of `A`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb45829",
   "metadata": {},
   "source": [
    "```python\n",
    "def chained_func(*args, **kwargs):\n",
    "```\n",
    "- Defines `chained_func`, which wraps the two functions being chained.\n",
    "- `*args, **kwargs` allow passing any number of arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78353f8",
   "metadata": {},
   "source": [
    "```python\n",
    "return next_runnable.execute(self.execute(*args, **kwargs))\n",
    "```\n",
    "\n",
    "- Calls `self.execute` (the first function in the chain).\n",
    "- Passes its output as input to `next_runnable.execute` (the next function in the chain).\n",
    "- Executes `next_runnable` immediately with the result from `self.execute`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837e513",
   "metadata": {},
   "source": [
    "```python\n",
    "return Runnable(chained_func)\n",
    "```\n",
    "- Returns a new `Runnable` instance containing `chained_func`, enabling further chaining.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fd480",
   "metadata": {},
   "source": [
    "### **3. Calling the Function (`invoke` Method)**\n",
    "\n",
    "```python\n",
    "def invoke(self, *args, **kwargs):  # Ensure invoke method exists\n",
    "        return self.func(*args, **kwargs)\n",
    "\n",
    "```\n",
    "- Defines `invoke`, allowing instances of `Runnable` to be called like functions.\n",
    "- When called, it executes the wrapped function (`self.func`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0113b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.execute = func  # Store the function\n",
    "\n",
    "\n",
    "    def __or__(self, next_runnable): # other is a Runnable object\n",
    "        def chained_func(*args, **kwargs):\n",
    "            # Ensure the result from self.func is passed to other.func correctly\n",
    "            return next_runnable.execute(self.execute(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "\n",
    "\n",
    "    def invoke(self, *args, **kwargs):  # Ensure invoke method exists\n",
    "        return self.execute(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2603882",
   "metadata": {},
   "source": [
    "## üëÄ Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94220f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions\n",
    "def add_five(x):\n",
    "    return x + 5\n",
    "\n",
    "\n",
    "def multiply_by_two(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "# Wrap the functions with Runnable\n",
    "add_five_runnable = Runnable(add_five)\n",
    "multiply_by_two_runnable = Runnable(multiply_by_two)\n",
    "\n",
    "\n",
    "# Chain the functions\n",
    "chain = add_five_runnable.__or__(multiply_by_two_runnable)  # First add 5, then multiply by 2\n",
    "\n",
    "\n",
    "# Invoke the chain\n",
    "chain.invoke(3)\n",
    "# Output: (3 + 5) * 2 = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b352bfc0",
   "metadata": {},
   "source": [
    "### Using `__or__` directly we get the correct answer, now let's try using the pipe operator `|` to chain them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1f2872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain the runnable functions together\n",
    "chain = add_five_runnable | multiply_by_two_runnable\n",
    "\n",
    "# invoke the chain\n",
    "chain.invoke(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
