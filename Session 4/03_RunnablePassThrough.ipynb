{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìå Passing Arguments Between Steps Using `RunnablePassthrough()`\n",
    "\n",
    "## **üîπ What is `RunnablePassthrough()`?**\n",
    "‚úÖ **`RunnablePassthrough()`** is a special `Runnable` that simply **forwards input to the next step without modification**.  \n",
    "‚úÖ It is useful for:\n",
    "- Passing **unchanged data** between steps.\n",
    "- Ensuring **multiple inputs** are available later in a workflow.\n",
    "- Keeping workflows **structured and readable**.\n",
    "\n",
    "\n",
    "https://python.langchain.com/docs/how_to/passthrough/\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üëÄ Example 1: Forwarding Input Without Modification**\n",
    "#### **Scenario:** Keep original input while transforming text in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_count': 3}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough, RunnableSequence\n",
    "\n",
    "\n",
    "# Step 1: Passthrough (Keep Original Text)\n",
    "passthrough = RunnablePassthrough()\n",
    "\n",
    "\n",
    "# Step 2: Convert text to uppercase\n",
    "uppercase_runnable = RunnableLambda(lambda x: {\"dupliacted text\": x[\"text\"]*2})\n",
    "\n",
    "\n",
    "# Step 3: Count words\n",
    "word_count_runnable = RunnableLambda(lambda x: {\"word_count\": len(x[\"dupliacted text\"].split())})\n",
    "\n",
    "\n",
    "\n",
    "# Workflow: Keep original text and transform it in parallel\n",
    "workflow = (\n",
    "        passthrough\n",
    "        | uppercase_runnable\n",
    "        | word_count_runnable\n",
    "            )\n",
    "\n",
    "# Run the workflow\n",
    "output = workflow.invoke({\"text\": \"Hello LangChain!\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üëÄ Example 2: Formatting the input to the next Runnable**\n",
    "#### **Scenario:** Output of the `RunnablePassthrough` is a string but the next Runnable needs a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read api_key from file\n",
    "with open('../api_keys.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "\n",
    "\n",
    "# Set loaded api_key as OPENAI_API_KEY environmental variable\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "But there were no secret treaties or political or financial commitments.\n",
      "\n",
      "The one supreme objective for the future, which we discussed for each Nation individually, and for all the United Nations, can be summed up in one word: Security.\n",
      "\n",
      "And that means not only physical security which provides safety from attacks by aggressors. It means also economic security, social security, moral security‚Äîin a family of Nations.\n",
      "\n",
      "In the plain down-to-earth talks that I had with the Generalissimo and Marshal Stalin and Prime Minister Churchill, it was abundantly clear that they are all most deeply interested in the resumption of peaceful progress by their own peoples‚Äîprogress toward a better life. All our allies want freedom to develop their lands and resources, to build up industry, to increase education and individual opportunity, and to raise standards of living.\n",
      "\n",
      "All our allies have learned by bitter experience that real development will not be possible if they are to be diverted from their purpose by repeated wars‚Äîor even threats of war.\n",
      "\n",
      "China and Russia are truly united with Britain and America in recognition of this essential fact:\n",
      "\n",
      "The best interests of each Nation, large and small, demand that all freedom-loving Nations shall join together in a just and durable system of peace. In the present world situation, evidenced by the actions of Germany, Italy, and Japan, unquestioned military control over disturbers of the peace is as necessary among Nations as it is among citizens in a community. And an equally basic essential to peace is a decent standard of living for all individual men and women and children in all Nations. Freedom from fear is eternally linked with freedom from want.\n",
      "\n",
      "There are people who burrow through our Nation like unseeing moles, and attempt to spread the suspicion that if other Nations are encouraged to raise their standards of living, our own American standard of living must of necessity be depressed.\n",
      "\n",
      "The fact is the very contrary. It has been shown time and again that if the standard of living of any country goes up, so does its purchasing power- and that such a rise encourages a better standard of living in neighboring countries with whom it trades. That is just plain common sense‚Äîand it is the kind of plain common sense that provided the basis for our discussions at Moscow, Cairo, and Teheran.\n"
     ]
    }
   ],
   "source": [
    "# Load the previously saved vectors\n",
    "chroma_vectorstore = Chroma(embedding_function = embedding_function, \n",
    "            persist_directory='../vector_stores/FDR_State_of_Union_Embeddings')\n",
    "\n",
    "\n",
    "# Create a retriever from the Chroma vector store\n",
    "retriever = chroma_vectorstore.as_retriever(search_kwargs={\"k\": 1})  # Retrieve top match\n",
    "\n",
    "\n",
    "query = \"How to achieve and enjoy good health?\"\n",
    "\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "print(len(retrieved_docs))\n",
    "\n",
    "\n",
    "# Print retrieved document contents\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- By focusing on physical security to ensure safety from attacks\n",
      "- By also focusing on economic security, social security, and moral security\n",
      "- By working towards a better life through peaceful progress, development, education, and individual opportunity\n",
      "- By joining together in a just and durable system of peace with all freedom-loving Nations\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question based only on the following context in a few bullet points in seperate lines:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# The prompt expects input with keys for \"context\" and \"question\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} # retriever output is a string, but we need to create a dic\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "\n",
    "Question =  \"How to achieve and enjoy good health?\"\n",
    "print(retrieval_chain.invoke(Question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•≥ **Congratulations! You created your first RAG system!**\n",
    "\n",
    "| **Component**           | **Role**                                           |\n",
    "|-------------------------|----------------------------------------------------|\n",
    "| `retriever`             | Gets relevant documents based on the question      |\n",
    "| `RunnablePassthrough()` | Passes the question through unchanged              |\n",
    "| `ChatPromptTemplate`    | Formats the prompt with context and question       |\n",
    "| `llm`                   | Generates an answer using the formatted prompt     |\n",
    "| `StrOutputParser()`     | Extracts the clean string output from the LLM      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **‚ö†Ô∏è Attention!**\n",
    "```python\n",
    "{\"context\": retriever,\n",
    " \"question\": RunnablePassthrough()}\n",
    "```\n",
    "\n",
    "- This is a **dictionary-style parallel runnable. (Implicit RunnableParallel via Dictionary)**\n",
    "- retriever is a Runnable (e.g. `.as_retriever()`) that takes the input question and returns relevant context.\n",
    "- `RunnablePassthrough()` passes the original question unchanged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
