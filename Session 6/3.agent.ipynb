{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc36e10",
   "metadata": {},
   "source": [
    "# **üïµÔ∏è‚Äç‚ôÇÔ∏è What is an Agent?**\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a router.\n",
    "\n",
    "* Our chat model will decide to make a tool call or not based upon the user input\n",
    "* We use a conditional edge to route to a node that will call our tool or simply end\n",
    "\n",
    "![Screenshot 2024-08-21 at 12.44.33 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbac0ba0bd34b541c448cc_agent1.png)\n",
    "\n",
    "\n",
    "In **LangChain** and **LangGraph**, an **Agent** is an intelligent, goal-directed entity that can **decide which tools to use and in what order** to accomplish a task. Think of it as a reasoning system powered by a language model that:\n",
    "- Receives an input (e.g. a question),\n",
    "- Plans what to do (e.g. search, compute, call APIs),\n",
    "- Executes steps using tools,\n",
    "- And returns the final answer.\n",
    "\n",
    "### Key Characteristics of an Agent:\n",
    "1. **Tool-using**: Agents can call external tools (e.g. web search, calculator, databases).\n",
    "2. **Iterative**: Agents can take multiple steps, reasoning at each one.\n",
    "3. **Stateful**: In LangGraph, agents can maintain memory/state across steps.\n",
    "\n",
    "### üß© How It Works\n",
    "\n",
    "![Screenshot 2024-08-21 at 12.45.43 PM.png](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6b27a8a7-8f67-4558-a3f4-44bf512e6c92_1766x812.gif)\n",
    "\n",
    "An agent is built on top of an LLM + a set of tools.\n",
    "\n",
    "At each step:\n",
    "- The LLM gets the task and current context.\n",
    "- It decides: *‚ÄúI should use the calculator with input 4 + 5.‚Äù*\n",
    "- LangChain executes that tool.\n",
    "- The result is fed back into the LLM.\n",
    "- Repeat until it reaches a final answer.\n",
    "\n",
    "### ‚úÖ When to Use Agents\n",
    "\n",
    "Use an agent when:\n",
    "- The task requires **decision-making** or **multiple steps**.\n",
    "- You don‚Äôt know ahead of time **which tools** or **what sequence** to use.\n",
    "- You want a more flexible, intelligent pipeline.\n",
    "\n",
    "### üß™ Example\n",
    "\n",
    "Say you ask:\n",
    "\n",
    "> ‚ÄúWhat‚Äôs the weather in Paris, and what‚Äôs the square root of the current temperature?‚Äù\n",
    "\n",
    "An agent would:\n",
    "1. Use a weather API tool to get Paris temperature (e.g. 64¬∞F).\n",
    "2. Use a calculator tool to compute ‚àö64.\n",
    "3. Return ‚ÄúThe square root of 64¬∞F is 8.‚Äù\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98f5e36a-da49-4ae2-8c74-b910a2f992fc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we can extend this into a generic agent architecture.\n",
    "\n",
    "In the above router, we invoked the model and, if it chose to call a tool, we returned a `ToolMessage` to the user.\n",
    " \n",
    "**But, what if we simply pass that `ToolMessage` *back to the model* ?**\n",
    "\n",
    "We can let it either \n",
    "1. call another tool \n",
    "2.  respond directly.\n",
    "\n",
    "This is the intuition behind **[ReAct](https://react-lm.github.io/), a general agent architecture.**\n",
    "  \n",
    "* `act` - let the model call specific tools \n",
    "* `observe` - pass the tool output back to the model \n",
    "* `reason` - let the model reason about the tool output to decide what to do next (e.g., call another tool or just respond directly)\n",
    "\n",
    "This [general purpose architecture](https://blog.langchain.dev/planning-for-agents/) can be applied to many types of tools. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63edff5a-724b-474d-9db8-37f0ae936c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bee8063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# read api_key from file\n",
    "with open(r'C:\\Users\\Seyed Barabadi\\Downloads\\Gen AI\\Incedo Teaching/api_keys.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "\n",
    "# Set loaded api_key as OPENAI_API_KEY environmental variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "api_key\n",
    "\n",
    "\n",
    "with open(r'C:\\Users\\Seyed Barabadi\\Downloads\\Gen AI\\Incedo Teaching/langsmith_api_key.txt', 'r') as file:\n",
    "    api_key = file.read()\n",
    "\n",
    "# Set loaded api_key as LANGSMITH_API_KEY environmental variable\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = api_key\n",
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356a6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba35a12",
   "metadata": {},
   "source": [
    "Here, we'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing).\n",
    "\n",
    "We'll log to a project, `langchain-academy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2801a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e6f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf6c3e9",
   "metadata": {},
   "source": [
    "### **üõ†Ô∏èDefine Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71795ff1-d6a7-448d-8b55-88bbd1ed3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# These are tools\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# For this ipynb we set parallel tool calling to false as math generally is done sequentially, and this time we have 3 tools that can do math\n",
    "# the OpenAI model specifically defaults to parallel tool calling for efficiency, see https://python.langchain.com/docs/how_to/tool_calling_parallel/\n",
    "# play around with it and see how the model behaves with math equations!\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)\n",
    "\n",
    "llm_with_tools_parallel = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cec014-3023-405c-be79-de8fc7adb346",
   "metadata": {},
   "source": [
    "Let's create our LLM and prompt it with the overall desired agent behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f486a8",
   "metadata": {},
   "source": [
    "### **üë§Create Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d061813f-ebc0-432c-91ec-3b42b15c30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState): # This assistant Node works as an Agent\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "   # return {\"messages\": [llm_with_tools_parallel.invoke([sys_msg] + state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb43343-9a6f-42cb-86e6-4380f928633c",
   "metadata": {},
   "source": [
    "As before, we use `MessagesState` and define a `Tools` node with our list of tools.\n",
    "\n",
    "The `Assistant` node is just our model with bound tools.\n",
    "\n",
    "We create a graph with `Assistant` and `Tools` nodes.\n",
    "\n",
    "We add `tools_condition` edge, which routes to `End` or to `Tools` based on  whether the `Assistant` calls a tool.\n",
    "\n",
    "Now, we add one new step:\n",
    "\n",
    "We connect the `Tools` node *back* to the `Assistant`, forming a loop.\n",
    "\n",
    "* After the `assistant` node executes, `tools_condition` checks if the model's output is a tool call.\n",
    "* If it is a tool call, the flow is directed to the `tools` node.\n",
    "* The `tools` node connects back to `assistant`.\n",
    "* This loop continues as long as the model decides to call tools.\n",
    "* If the model response is not a tool call, the flow is directed to END, terminating the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362f636",
   "metadata": {},
   "source": [
    "### **üåêBuild The Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aef13cd4-05a6-4084-a620-2e7b91d9a72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define Nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "\n",
    "# Define Edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75602459-d8ca-47b4-9518-3f38343ebfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [HumanMessage(content=\"Add 3 and 4. Multiply the output by 2. Divide the output by 5\")]\n",
    "\n",
    "messages = [HumanMessage(content=\"Add 3 and 4, then Multiply it by 2 and divide the result by 5\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b517142d-c40c-48bf-a5b8-c8409427aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4, then Multiply it by 2 and divide the result by 5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_fk9UAyBBytEpZ2RT7qTqXkhN)\n",
      " Call ID: call_fk9UAyBBytEpZ2RT7qTqXkhN\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: add\n",
      "\n",
      "7\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_v6gemmFnpEHSwSkGxFNETPOK)\n",
      " Call ID: call_v6gemmFnpEHSwSkGxFNETPOK\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "14\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  divide (call_E118KKWxSrSQ3faOm4vEz5Cx)\n",
      " Call ID: call_E118KKWxSrSQ3faOm4vEz5Cx\n",
      "  Args:\n",
      "    a: 14\n",
      "    b: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: divide\n",
      "\n",
      "2.8\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of adding 3 and 4, then multiplying it by 2, and finally dividing the result by 5 is 2.8.\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf74e6a",
   "metadata": {},
   "source": [
    "## **üß†üí™Reasoning**\n",
    "- Using `\"gpt-4o\"` instead of `\"gpt-3.5-turbo\"` as the model brain can drastically enhance the resoning ability of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05c3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# For this ipynb we set parallel tool calling to false as math generally is done sequentially, and this time we have 3 tools that can do math\n",
    "# the OpenAI model specifically defaults to parallel tool calling for efficiency, see https://python.langchain.com/docs/how_to/tool_calling_parallel/\n",
    "# play around with it and see how the model behaves with math equations!\n",
    "llm_with_tools_gpt_4 = llm.bind_tools(tools, parallel_tool_calls=False)\n",
    "\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState): # This assistant Node works as an Agent\n",
    "   return {\"messages\": [llm_with_tools_gpt_4.invoke([sys_msg] + state[\"messages\"])]}\n",
    "   # return {\"messages\": [llm_with_tools_parallel.invoke([sys_msg] + state[\"messages\"])]\n",
    "\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define Nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "\n",
    "# Define Edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "\n",
    "react_graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bd42233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Find the average of 8 and 6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To find the average of two numbers, you add them together and divide the sum by 2.\n",
      "\n",
      "Let's calculate:\n",
      "\n",
      "1. Add the numbers: \\(8 + 6 = 14\\).\n",
      "2. Divide the sum by 2: \\(\\frac{14}{2} = 7\\).\n",
      "\n",
      "So, the average of 8 and 6 is 7.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Find the average of 8 and 6\")]\n",
    "messages = react_graph.invoke({\"messages\": messages})\n",
    "\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad869f22-9bfb-4cbe-9f30-8a307c5cdda2",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "\n",
    "We can look at traces in LangSmith at https://www.langchain.com/langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663b179",
   "metadata": {},
   "source": [
    "## **Example**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd7eef",
   "metadata": {},
   "source": [
    "`%pip install --upgrade --quiet langchain-community`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c3699",
   "metadata": {},
   "source": [
    "## **Brave Search**\n",
    "- https://python.langchain.com/docs/integrations/tools/brave_search/\n",
    "- https://brave.com/search/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad03fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import BraveSearch\n",
    "\n",
    "api_key = \"BSATADsn2zgJtIVoYHaMWM9Tx4k1qW8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e64289b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = BraveSearch.from_api_key(api_key=api_key, search_kwargs={\"count\": 1})\n",
    "\n",
    "# or if you want to get the api key from environment variable BRAVE_SEARCH_API_KEY, and leave search_kwargs empty\n",
    "# tool = BraveSearch()\n",
    "\n",
    "# or if you want to provide just the api key, and leave search_kwargs empty\n",
    "# tool = BraveSearch.from_api_key(api_key=api_key)\n",
    "\n",
    "# or if you want to provide just the search_kwargs and read the api key from the BRAVE_SEARCH_API_KEY environment variable\n",
    "# tool = BraveSearch.from_search_kwargs(search_kwargs={\"count\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c506c96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"title\": \"Obama\\\\u2019s Middle Name \\\\u2014 My Last Name \\\\u2014 is \\\\u2018Hussein.\\\\u2019 So?\", \"link\": \"https://www.cair.com/cair_in_the_news/obamas-middle-name-my-last-name-is-hussein-so/\", \"snippet\": \"I was. Granted, it was only a school play, and I spell my name \\\\u201c<strong>Hussain</strong>.\\\\u201d But I thought I did a pretty good job as the commander in chief, even if my wardrobe consisted of an old tweed jacket from Sears.\"}]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_result = tool.invoke(\"obama middle name\")\n",
    "obama_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2860d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Obama‚Äôs Middle Name ‚Äî My Last Name ‚Äî is ‚ÄòHussein.‚Äô So?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Step 1: Convert string to Python list\n",
    "parsed_result = json.loads(obama_result)\n",
    "\n",
    "# Step 2: Now you can access like a list of dicts\n",
    "Obama_title = parsed_result[0][\"title\"]\n",
    "Obama_link = parsed_result[0][\"link\"]\n",
    "Obama_snippet = parsed_result[0][\"snippet\"]\n",
    "print(\"Title:\", Obama_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31425252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_snippet(search_result: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans a search result snippet by:\n",
    "    - Removing HTML tags (e.g., <strong>, <br>, etc.)\n",
    "    - Removing line breaks\n",
    "    - Stripping extra whitespace\n",
    "    \"\"\"\n",
    "    # Step 1: Convert string to Python list\n",
    "    parsed_result = json.loads(search_result)\n",
    "\n",
    "    # Step 2: Now you can access like a list of dicts\n",
    "    title = parsed_result[0][\"title\"]\n",
    "    link = parsed_result[0][\"link\"]\n",
    "    snippet = parsed_result[0][\"snippet\"]\n",
    "\n",
    "    cleaned_output = {}\n",
    "\n",
    "   \n",
    "    for k, v in parsed_result[0].items():\n",
    "         # Remove HTML tags\n",
    "        no_html = re.sub(r\"<.*?>\", \"\", v)\n",
    "\n",
    "        # Replace multiple spaces or newlines with a single space\n",
    "        cleaned = re.sub(r\"\\s+\", \" \", no_html)\n",
    "\n",
    "        cleaned_output[k] = cleaned.strip()\n",
    "\n",
    "    return cleaned_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c13215cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Obama‚Äôs Middle Name ‚Äî My Last Name ‚Äî is ‚ÄòHussein.‚Äô So?',\n",
       " 'link': 'https://www.cair.com/cair_in_the_news/obamas-middle-name-my-last-name-is-hussein-so/',\n",
       " 'snippet': 'I was. Granted, it was only a school play, and I spell my name ‚ÄúHussain.‚Äù But I thought I did a pretty good job as the commander in chief, even if my wardrobe consisted of an old tweed jacket from Sears.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cleaned_output = clean_snippet(obama_result)\n",
    "cleaned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae5d5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_result = tool.invoke(\"How old is Brad Pitt?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbd6f7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Brad Pitt - Wikipedia',\n",
       " 'link': 'https://en.wikipedia.org/wiki/Brad_Pitt',\n",
       " 'snippet': 'William Bradley Pitt (born December 18, 1963) is an American actor and film producer. He is the recipient of various accolades, including two Academy Awards, two British Academy Film Awards, two Golden Globe Awards, and a Primetime Emmy Award. One of the most influential celebrities, Pitt appeared ...'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_snippet(bp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dcacc0",
   "metadata": {},
   "source": [
    "## **Tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4c9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions needed to create llm_with_tools\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    add a to b and return the result\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    multiply a to b and return the result\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "float\n",
    "def divide(a: float, b: float) ->float:\n",
    "    \"\"\"\n",
    "    divide a to b and return the result\n",
    "    \"\"\"\n",
    "    return a / b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e478b",
   "metadata": {},
   "source": [
    "## **Nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4d001fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import BraveSearch\n",
    "\n",
    "# define serach functions needed to create llm_with_tools and Search node\n",
    "api_key = \"BSATADsn2zgJtIVoYHaMWM9Tx4k1qW8\"\n",
    "search_tool = BraveSearch.from_api_key(api_key=api_key, search_kwargs={\"count\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c4a44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f237113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Define Tools\n",
    "tools = [add, multiply, divide, search_tool]\n",
    "\n",
    "\n",
    "# Bind tools with llm\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "# define Tool node\n",
    "tools = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "805c8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reasoner node\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "reasoner_system_message = SystemMessage(content=\"You are a helpful assistant tasked with using search and performing arithmetic on a set of inputs.\")\n",
    "\n",
    "\n",
    "def reasoner(state: MessagesState) :\n",
    "    return {'messages': [llm_with_tools.invoke([reasoner_system_message] + state['messages'])]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e9f4f",
   "metadata": {},
   "source": [
    "## **Build the Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "016df915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grpah\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition # this is the checker for the if you got a tool back\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder.add_node(\"reasoner\", reasoner)\n",
    "builder.add_node(\"tools\", tools)\n",
    "\n",
    "builder.add_edge(START, \"reasoner\")\n",
    "builder.add_conditional_edges(\"reasoner\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"reasoner\")\n",
    "\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Display the graph\n",
    "# display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63f3f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = react_graph.invoke({\"messages\": HumanMessage(content=\"What is 2 times Brad Pitt's age?\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dfbf92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is 2 times Brad Pitt's age?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  brave_search (call_OV8Iiqo5QuBDSpS06zUQ3FpA)\n",
      " Call ID: call_OV8Iiqo5QuBDSpS06zUQ3FpA\n",
      "  Args:\n",
      "    query: Brad Pitt age 2023\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: brave_search\n",
      "\n",
      "[{\"title\": \"Brad Pitt - Wikipedia\", \"link\": \"https://en.wikipedia.org/wiki/Brad_Pitt\", \"snippet\": \"William Bradley Pitt (<strong>born December 18, 1963</strong>) is an American actor and film producer. He is the recipient of various accolades, including two Academy Awards, two British Academy Film Awards, two Golden Globe Awards, and a Primetime Emmy Award. One of the most influential celebrities, Pitt appeared ...\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Brad Pitt was born on December 18, 1963. As of 2023, he is 59 years old. Let's calculate 2 times his age.\n",
      "Tool Calls:\n",
      "  multiply (call_wN5CZGCmMgTks7IZqhaQDjVd)\n",
      " Call ID: call_wN5CZGCmMgTks7IZqhaQDjVd\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 59\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "118.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2 times Brad Pitt's age is 118.\n"
     ]
    }
   ],
   "source": [
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0131c65c",
   "metadata": {},
   "source": [
    "## **Let's create our own custom `StateGraph`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43d045",
   "metadata": {},
   "source": [
    "`%pip install yfinance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcc41bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "def get_stock_price(ticker: str) -> float:\n",
    "    \"\"\"Gets a stock price from Yahoo Finance.\n",
    "\n",
    "    Args:\n",
    "        ticker: ticker str\n",
    "    \"\"\"\n",
    "    # \"\"\"This is a tool for getting the price of a stock when passed a ticker symbol\"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    return stock.info['previousClose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16a3cb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202.52"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51ba4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    query: str\n",
    "    finance: str\n",
    "    final_answer: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Or\n",
    "\n",
    "\n",
    "class GraphState(MessagesState):\n",
    "    query: str\n",
    "    finance: str\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e249bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply, divide, search_tool, get_stock_price]\n",
    "\n",
    "\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a6f000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def reasoner(state: GraphState)-> GraphState:\n",
    "    sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with using search, the yahoo finance tool and performing arithmetic on a set of inputs.\")\n",
    "    user_query_msg = HumanMessage(content=state['query']) \n",
    "\n",
    "    all_input_messages = [  # includes all the inputs for LLM call\n",
    "                          sys_msg,\n",
    "                          *state[\"messages\"], # *state[\"messages\"] is empty initillay\n",
    "                          user_query_msg\n",
    "                          ] \n",
    "    \n",
    "    result = llm_with_tools.invoke(all_input_messages)\n",
    "    \n",
    "    return {'messages': [result] }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e47fa9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GraphState)\n",
    "\n",
    "builder.add_node('tools', tool_node)\n",
    "builder.add_node('reasoner', reasoner)\n",
    "\n",
    "builder.add_edge(START, \"reasoner\")\n",
    "builder.add_conditional_edges(\"reasoner\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"reasoner\")\n",
    "\n",
    "react_graph = builder.compile()\n",
    "\n",
    "# Show\n",
    "# display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7432a839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Brad Pitt was born on December 18, 1963. Therefore, he is currently 59 years old (as of 2023). \n",
      "\n",
      "2 times Brad Pitt's age (59 years) is 118.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = react_graph.invoke({\"query\": \"What is 2 times Brad Pitt's age?\"})\n",
    "response['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47f57d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  brave_search (call_ZXS7icMhbBKK5hrn6ok5q4I9)\n",
      " Call ID: call_ZXS7icMhbBKK5hrn6ok5q4I9\n",
      "  Args:\n",
      "    query: company where Jensen Huang is CEO\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: brave_search\n",
      "\n",
      "[{\"title\": \"Jensen Huang - Wikipedia\", \"link\": \"https://en.wikipedia.org/wiki/Jensen_Huang\", \"snippet\": \"Jen-Hsun &quot;Jensen&quot; Huang (Chinese: \\u9ec3\\u4ec1\\u52f3; pinyin: Hu\\u00e1ng R\\u00e9nx\\u016bn; Pe\\u030dh-\\u014de-j\\u012b: N\\u0302g J\\u00een-hun; born February 17, 1963) is a Taiwanese and American businessman, electrical engineer, and philanthropist who is the president, co-founder, and chief executive officer (CEO) of <strong>Nvidia</strong>, the world&#x27;s ...\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_stock_price (call_FnbN3ghLMfyRmXQPZI30SGDO)\n",
      " Call ID: call_FnbN3ghLMfyRmXQPZI30SGDO\n",
      "  Args:\n",
      "    ticker: NVDA\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_stock_price\n",
      "\n",
      "110.71\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The stock price of Nvidia, the company where Jensen Huang is the CEO, is $110.71.\n"
     ]
    }
   ],
   "source": [
    "response = react_graph.invoke({\"query\": \"What is the stock price of the company that Jensen Huang is CEO of?\"})\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb51528c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_stock_price (call_ctZYXIhxt7gn9JEZBfBcg3HC)\n",
      " Call ID: call_ctZYXIhxt7gn9JEZBfBcg3HC\n",
      "  Args:\n",
      "    ticker: NVDA\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_stock_price\n",
      "\n",
      "110.71\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_hI3rkwok85NIEjo9btHJ9ByF)\n",
      " Call ID: call_hI3rkwok85NIEjo9btHJ9ByF\n",
      "  Args:\n",
      "    a: 110.71\n",
      "    b: 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "221.42\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "If the price of NVIDIA stock doubles, it will be $221.42.\n"
     ]
    }
   ],
   "source": [
    "response = react_graph.invoke({\"query\": \"What will be the price of nvidia stock if it doubles?\"})\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d18228a",
   "metadata": {},
   "source": [
    "## ‚úÖ Key Differences Between calling a function as a Node and a Tool\n",
    "\n",
    "| Feature                           | Function Calling as a Node                 | Tool (`@tool`) Function                     |\n",
    "|-----------------------------------|--------------------------------------------|---------------------------------------------|\n",
    "| **Invoked by...**                 | You (via LangGraph edges)                  | The LLM (via `tool_calls`)                  |\n",
    "| **Input format**                  | `state: State`                             | Explicit arguments (e.g., `a: int`)         |\n",
    "| **Purpose**                       | Part of graph flow                         | Model-usable external function              |\n",
    "| **Tool metadata?**                | ‚ùå No                                       | ‚úÖ Yes (name, description)                   |\n",
    "| **Automatically selected by LLM?**| ‚ùå No                                       | ‚úÖ Yes                                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf621b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
