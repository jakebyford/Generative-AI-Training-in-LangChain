{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc2b327-0bfe-41f7-9e9f-753da359b976",
   "metadata": {},
   "source": [
    "# Understanding Retrievers in RAG Systems\n",
    "\n",
    "### Introduction\n",
    "Welcome to our exploration of retrievers in Retrieval Augmented Generation (RAG) systems. This notebook demonstrates how to build a simple yet powerful retrieval system that can search through documents and find relevant information based on user queries.\n",
    "\n",
    "### What are Retrievers?\n",
    "Retrievers are components in RAG systems that search through a document collection to find information relevant to a query. They serve as the \"memory\" for large language models, allowing them to access and reference specific information beyond their training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3111377a-e0c9-4d80-9744-a15f64f13355",
   "metadata": {},
   "source": [
    "### Step 1: Setting Up Our Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14008f80-c1ca-4006-9cfb-8cf88bc6346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd38747-5cba-4335-b17e-020b13b473e9",
   "metadata": {},
   "source": [
    "These imports give us access to:\n",
    "\n",
    "- Document loaders for different file types\n",
    "- FAISS for efficient similarity search\n",
    "- OpenAI's embedding model to convert text to vectors\n",
    "- Text splitters to break documents into manageable chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29844c-9b44-47e8-ba9d-12c38f060ad5",
   "metadata": {},
   "source": [
    "### Step 2: The RAG Pipeline Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd43fa53-e364-4228-97d5-3b302692a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DOCUMENT --> SPLIT CHUNKS\n",
    "\n",
    "# EMBEDDING --> EMBED CHUNKS --> VECTORS\n",
    "\n",
    "# VECTOR CHUNKS -- SAVE DB\n",
    "\n",
    "# \"query\" --> similarity search faiss db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831cc08-e007-4e62-aeda-d521a2cd892b",
   "metadata": {},
   "source": [
    "This represents the typical workflow of a RAG system:\n",
    "\n",
    "1. Load documents and split into chunks\n",
    "2. Convert text chunks into vector embeddings\n",
    "3. Store these vectors in a database\n",
    "4. Perform similarity search when given a query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555fd846-ed92-411a-ba31-d9ecad2bacf9",
   "metadata": {},
   "source": [
    "### Step 3: Loading and Chunking Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d094002-8885-46c9-84b7-d3ab069ffcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader('../test.txt', encoding = 'UTF-8')\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "    )\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a7187-8405-42ee-bc68-76b693a7ccbc",
   "metadata": {},
   "source": [
    "Here we:\n",
    "\n",
    "- Load a text document\n",
    "- Split it into smaller chunks of 500 characters\n",
    "- Use a 100-character overlap to maintain context between chunks\n",
    "- Define separators to ensure chunks break at natural boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8aca239-065b-4c61-a379-b5052a3d2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc47290e-dbe5-4328-bcee-d49e1fb577db",
   "metadata": {},
   "source": [
    "### Step 4: Setting Up the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c3ac16-818f-48cf-ad7d-79f66d4bd9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb5e03-4587-4bed-b7e4-578739f65c90",
   "metadata": {},
   "source": [
    "The embedding model transforms text into numerical vectors that capture semantic meaning, allowing our system to understand and compare text based on meaning rather than just keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a069a-bf20-437f-844c-3376d39a7b93",
   "metadata": {},
   "source": [
    "### Step 5: Creating the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b822f871-509b-4ba3-87e7-8006626b17c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef4761-e193-426a-b028-c9d148b27c3a",
   "metadata": {},
   "source": [
    "FAISS (Facebook AI Similarity Search) is a library for efficient similarity search. This code:\n",
    "\n",
    "- Takes our document chunks\n",
    "- Uses the embedding model to convert them to vectors\n",
    "- Creates a searchable database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ee1a1-7526-4915-98f1-0073865a0382",
   "metadata": {},
   "source": [
    "### Step 6: Saving Our Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76dc8b0-5d84-41b6-a46a-054bbab7f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/vectorstores/faiss/#saving-and-loading\n",
    "vector_db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8090f9-a22b-439d-aacf-e2e9f7d4179f",
   "metadata": {},
   "source": [
    "This allows us to save our work and reuse the vector database without having to recreate it from scratch each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c807d-8d30-4b32-832f-76ed2c8ae8cf",
   "metadata": {},
   "source": [
    "### Step 7: Loading a Previously Created Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb1a7f33-d382-46bc-81be-f6d2b0394145",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector_store = FAISS.load_local(\n",
    "    \"faiss_index\", embedding_model, allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584f281-7b84-48fd-b8a6-c17981f4bd38",
   "metadata": {},
   "source": [
    "This is where we'd typically pick up if we already have a prepared database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ffa7df-eb21-4276-be0f-cb1265a025ae",
   "metadata": {},
   "source": [
    "### Step 8: Creating a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f2dff65-a568-4195-b6cd-fbcaa05ef8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = new_vector_store.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs = {\"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a21b87b-edec-44c8-9232-a3378001ac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='dbbfd0f3-a413-4d32-9f5f-a43cd8c7ff0f', metadata={'source': '../test.txt'}, page_content='Decorative Styles:\\nGeometric Style (900-700 BCE): Features abstract patterns and motifs.\\nBlack-Figure Technique (700-500 BCE): Figures are painted in black silhouette against the natural red clay.\\nRed-Figure Technique (530-300 BCE): The reverse of black-figure, allowing for greater detail and expression.\\nPainting\\nWhile few examples survive, Greek painting was highly esteemed, with influences seen in vase paintings and frescoes.\\nTechniques: Included fresco, encaustic, and tempera.'),\n",
       "  np.float32(0.26161647)),\n",
       " (Document(id='b3967691-beec-495d-bc51-276068f62ab5', metadata={'source': '../test.txt'}, page_content='Sculpture and Pottery\\nGreek sculptors excelled in creating lifelike statues that captured the human form with remarkable realism and beauty. Works such as the Venus de Milo and the Discobolus exemplify the Greek pursuit of idealized proportions and expressive detail. Pottery was another significant art form, featuring intricate designs and scenes from mythology and everyday life that provide valuable insights into Greek culture.\\nArchitectural Marvels'),\n",
       "  np.float32(0.27237347)),\n",
       " (Document(id='fc039af3-f625-41bf-aff8-230d6827ae9c', metadata={'source': '../test.txt'}, page_content='Techniques: Included fresco, encaustic, and tempera.\\nThemes: Mythological narratives, daily life, and natural landscapes.\\nArchitecture\\nGreek architecture is celebrated for its harmony, proportion, and grandeur, with enduring influences on Western architectural styles.\\nThe Three Orders: Doric, Ionic, and Corinthian, each with distinct column designs and decorative elements.\\nDoric Order: Simple, sturdy columns with plain capitals.\\nIonic Order: Slender columns with scroll-like capitals.'),\n",
       "  np.float32(0.29397735)),\n",
       " (Document(id='f1cbbe84-8176-44f8-aa79-910dced54622', metadata={'source': '../test.txt'}, page_content='The arts and culture of ancient Greece represent a vibrant and dynamic facet of its civilization, showcasing unparalleled creativity and intellectual rigor. From the timeless sculptures that capture the human form and spirit to the profound philosophical inquiries into existence and morality, Greek cultural achievements continue to inspire and inform contemporary society'),\n",
       "  np.float32(0.3052978))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vector_store.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c07a4b7-a649-4d4d-acec-cc54263583f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    docs, scores = zip(*new_vector_store.similarity_search_with_score(query))\n",
    "    for doc, score in zip(docs, scores):\n",
    "        doc.metadata[\"score\"] = score\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee1585a-aa65-429b-935b-480d2497d68f",
   "metadata": {},
   "source": [
    "The retriever performs the actual search:\n",
    "\n",
    "- We're using similarity search (finding semantically similar content)\n",
    "- We're retrieving the top 3 most relevant chunks for each query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86040f63-cd77-410f-a6d4-d6426c89bca1",
   "metadata": {},
   "source": [
    "### Step 9: Testing Our Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b8e1825-7bc4-43d4-81e2-b032f3e51941",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument 'text': 'list' object cannot be converted to 'PyString'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m queries \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you give some decorative styles in ancient Greek life?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you give the last United States election results?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m ]\n\u001b[0;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m queries\n\u001b[1;32m----> 8\u001b[0m retrievals \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1074\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1072\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_kwargs \u001b[38;5;241m|\u001b[39m kwargs\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1074\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1076\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1077\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search_with_relevance_scores(\n\u001b[0;32m   1078\u001b[0m             query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs\n\u001b[0;32m   1079\u001b[0m         )\n\u001b[0;32m   1080\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:643\u001b[0m, in \u001b[0;36mFAISS.similarity_search\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search\u001b[39m(\n\u001b[0;32m    624\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    625\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    630\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    631\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 643\u001b[0m     docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:515\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[1;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    493\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    498\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[0;32m    499\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \n\u001b[0;32m    501\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[0;32m    517\u001b[0m         embedding,\n\u001b[0;32m    518\u001b[0m         k,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    522\u001b[0m     )\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:266\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function, Embeddings):\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function(text)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:629\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \n\u001b[0;32m    623\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m        Embedding for the text.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:480\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mGenerate length-safe embeddings for a list of texts.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;124;03m    List[List[float]]: A list of embeddings for each input text.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    479\u001b[0m _chunk_size \u001b[38;5;241m=\u001b[39m chunk_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size\n\u001b[1;32m--> 480\u001b[0m _iter, tokens, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:441\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._tokenize\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    439\u001b[0m     token \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mencode(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoder_kwargs)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[43mencoding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_ordinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Split tokens into chunks respecting the embedding_ctx_length\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(token), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ctx_length):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tiktoken\\core.py:73\u001b[0m, in \u001b[0;36mEncoding.encode_ordinary\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Encodes a string into tokens, ignoring special tokens.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03mThis is equivalent to `encode(text, disallowed_special=())` (but slightly faster).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m[31373, 995]\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_core_bpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_ordinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m# See comment in encode\u001b[39;00m\n\u001b[0;32m     76\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: argument 'text': 'list' object cannot be converted to 'PyString'"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Can you give some decorative styles in ancient Greek life?\",\n",
    "    \"Can you give the last United States election results?\"\n",
    "]\n",
    "\n",
    "query = queries\n",
    "\n",
    "retrievals = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ed63d-cc48-4dd1-bcd0-98d3acbfd20c",
   "metadata": {},
   "source": [
    "Here we test our retriever with a query about ancient Greek decorative styles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1b29e-28f0-4461-bae7-9577c2ff97f8",
   "metadata": {},
   "source": [
    "### Step 10: Examining the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7beade0e-9b89-4b59-a627-b1cd30155867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Document(id='dbbfd0f3-a413-4d32-9f5f-a43cd8c7ff0f', metadata={'source': '../test.txt', 'score': np.float32(0.26161647)}, page_content='Decorative Styles:\\nGeometric Style (900-700 BCE): Features abstract patterns and motifs.\\nBlack-Figure Technique (700-500 BCE): Figures are painted in black silhouette against the natural red clay.\\nRed-Figure Technique (530-300 BCE): The reverse of black-figure, allowing for greater detail and expression.\\nPainting\\nWhile few examples survive, Greek painting was highly esteemed, with influences seen in vase paintings and frescoes.\\nTechniques: Included fresco, encaustic, and tempera.'),\n",
       " Document(id='b3967691-beec-495d-bc51-276068f62ab5', metadata={'source': '../test.txt', 'score': np.float32(0.27237347)}, page_content='Sculpture and Pottery\\nGreek sculptors excelled in creating lifelike statues that captured the human form with remarkable realism and beauty. Works such as the Venus de Milo and the Discobolus exemplify the Greek pursuit of idealized proportions and expressive detail. Pottery was another significant art form, featuring intricate designs and scenes from mythology and everyday life that provide valuable insights into Greek culture.\\nArchitectural Marvels'),\n",
       " Document(id='fc039af3-f625-41bf-aff8-230d6827ae9c', metadata={'source': '../test.txt', 'score': np.float32(0.29397735)}, page_content='Techniques: Included fresco, encaustic, and tempera.\\nThemes: Mythological narratives, daily life, and natural landscapes.\\nArchitecture\\nGreek architecture is celebrated for its harmony, proportion, and grandeur, with enduring influences on Western architectural styles.\\nThe Three Orders: Doric, Ionic, and Corinthian, each with distinct column designs and decorative elements.\\nDoric Order: Simple, sturdy columns with plain capitals.\\nIonic Order: Slender columns with scroll-like capitals.'),\n",
       " Document(id='f1cbbe84-8176-44f8-aa79-910dced54622', metadata={'source': '../test.txt', 'score': np.float32(0.3052978)}, page_content='The arts and culture of ancient Greece represent a vibrant and dynamic facet of its civilization, showcasing unparalleled creativity and intellectual rigor. From the timeless sculptures that capture the human form and spirit to the profound philosophical inquiries into existence and morality, Greek cultural achievements continue to inspire and inform contemporary society'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrievals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5374ef-3819-4a88-a63a-7fcdc3f6684e",
   "metadata": {},
   "source": [
    "This displays the top 3 most relevant document chunks from our database. Notice how they all relate to Greek decorative styles, even though they might not contain the exact wording of our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a25e9-3ebc-4cd7-aa33-f72d2530762e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "700d546c-6512-4592-89f3-85c9ea18f0aa",
   "metadata": {},
   "source": [
    "### Advanced Implementation: Complete RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534ab42-85e1-4a51-ba93-7bd9b23f3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schema = [\n",
    "    ResponseSchema(name=\"summary\", description=\"A concise summary of the wikipedia page\"),\n",
    "    ResponseSchema(name=\"key_points\", description=\"The key points relevant to the query\"),\n",
    "    ResponseSchema(name=\"wikipedia_reference\", description=\"Relevant information retrieved from Wikipedia\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "context = \"\\n\".join([doc.page_content for doc in retrievals])\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert assistant. Based on the following context, generate a structured response:\n",
    "\n",
    "Context: {context}\n",
    "Wikipedia: {wiki_data}\n",
    "{format_instructions}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11737d90-f018-4d2a-8265-1e07a37a72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_chunk(file_path, chunk_size=500, chunk_overlap=100):\n",
    "    print(\"Loading and Splitting the PDF Document...\")\n",
    "\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "    )\n",
    "\n",
    "    chunk = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(f\"Number of chunks: {len(chunk)}\")\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652b068-1b56-46ec-8cc9-d37fec0453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_database(chunks):\n",
    "    print(\"Creating FAISS Index...\")\n",
    "    vector_db = FAISS.from_documents(chunks, embedding_model)\n",
    "    print(\"FAISS Index Created\")\n",
    "    return vector_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfa7863-efec-4e94-9e8e-6a767f1a7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Starting Complete RAG Demo \")\n",
    "\n",
    "file_path = \"../../ai-report.pdf\"\n",
    "chunks = load_and_chunk(file_path)\n",
    "vector_db = create_vector_database(chunks)\n",
    "\n",
    "queries = [\n",
    "    \"What examples of AI-driven solutions in tutoring are given?\"\n",
    "]\n",
    "\n",
    "query = queries[0]\n",
    "\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs = {\"k\": 3}\n",
    ")\n",
    "\n",
    "retrievals = retriever.get_relevant_documents(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
