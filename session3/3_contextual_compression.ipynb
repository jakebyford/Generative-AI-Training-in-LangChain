{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c37a56a-9ff7-4786-be4b-586215f0be16",
   "metadata": {},
   "source": [
    "## Setting Up Our Environment\n",
    "\n",
    "\n",
    "Don't forget to run ```export OPENAI_API_KEY=sk-...``` to set your api key in the environment variables before running Jupyter. You can set up alternative api keys with hugging face or other client sites to operate with LangChain but that is beyond our scope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d504e9f-1ac5-4940-9566-4836adc330f8",
   "metadata": {},
   "source": [
    "# Why We Need Compression in Retrieval Systems\n",
    "Compression in retrieval systems addresses several critical challenges:\n",
    "\n",
    "1. <b>Relevance Filtering</b>:\n",
    "   - When you ingest documents into a retrieval system, you typically don't know what specific queries users will make. This means retrieved documents often contain a mix of relevant and irrelevant information.\n",
    "2. <b>Cost Efficiency</b>:\n",
    "   - Passing entire documents through LLMs is expensive. Compression reduces the amount of text processed, lowering costs for API-based LLM services.\n",
    "3. <b>Response Quality</b>:\n",
    "   - Providing LLMs with concise, relevant context leads to better responses. Irrelevant information can confuse the model and result in lower quality outputs.\n",
    "4. <b>Processing Speed</b>:\n",
    "   - Shorter documents mean faster processing times, improving overall system performance.\n",
    "5. <b>Context Window Optimization</b>:\n",
    "   - LLMs have limited context windows. Compression helps maximize the use of available tokens by focusing only on the most relevant content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612eac0a",
   "metadata": {
    "id": "612eac0a"
   },
   "source": [
    "# How to do retrieval with contextual compression\n",
    "\n",
    "One challenge with [retrieval](/docs/concepts/retrieval/) is that usually you don't know the specific queries your document storage system will face when you ingest data into the system. This means that the information most relevant to a query may be buried in a document with a lot of irrelevant text. Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "<b>Contextual compression</b> is meant to fix this. \n",
    "\n",
    "The idea is simple: instead of immediately returning retrieved documents as-is, you can compress them using the context of the given query, so that only the relevant information is returned. “Compressing” here refers to both compressing the contents of an individual document and filtering out documents.\n",
    "\n",
    "To use the Contextual Compression Retriever, you'll need:\n",
    "\n",
    "- a base [retriever](https://python.langchain.com/api_reference/core/retrievers/langchain_core.retrievers.BaseRetriever.html#langchain_core.retrievers.BaseRetriever)\n",
    "- a [Document Compressor](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.compressor.BaseDocumentCompressor.html)\n",
    "\n",
    "The Contextual Compression Retriever passes queries to the base retriever, takes the initial documents and passes them through the Document Compressor. The Document Compressor takes a list of documents and shortens it by reducing the contents of documents or dropping documents altogether.\n",
    "\n",
    "## Get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0029369",
   "metadata": {
    "id": "e0029369"
   },
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2360fc",
   "metadata": {
    "id": "9d2360fc"
   },
   "source": [
    "## Using a vanilla vector store retriever\n",
    "Let's start by initializing a simple vector store retriever and storing the 2023 State of the Union speech (in chunks). We can see that given an example question our retriever returns one or two relevant docs and a few irrelevant docs. And even the relevant docs have a lot of irrelevant information in them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c26947-958d-4219-8ca0-daa3a51bd344",
   "metadata": {
    "id": "25c26947-958d-4219-8ca0-daa3a51bd344",
    "outputId": "2164a778-d816-4767-96d2-765e54c80a2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1535, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "The foreign policy that we have been followingâ€”the policy that guided us at Moscow, Cairo, and Teheranâ€”is based on the common sense principle which was best expressed by Benjamin Franklin on July 4, 1776: \"We must all hang together, or assuredly we shall all hang separately.\"\n",
      "\n",
      "I have often said that there are no two fronts for America in this war. There is only one front. There is one line of unity which extends from the hearts of the people at home to the men of our attacking forces in our farthest outposts. When we speak of our total effort, we speak of the factory and the field, and the mine as well as of the battleground -- we speak of the soldier and the civilian, the citizen and his Government.\n",
      "\n",
      "Each and every one of us has a solemn obligation under God to serve this Nation in its most critical hourâ€”to keep this Nation great -- to make this Nation greater in a better world.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Let us remember the lessons of 1918. In the summer of that year the tide turned in favor of the allies. But this Government did not relax. In fact, our national effort was stepped up. In August, 1918, the draft age limits were broadened from 21-31 to 18-45. The President called for \"force to the utmost,\" and his call was heeded. And in November, only three months later, Germany surrendered.\n",
      "\n",
      "That is the way to fight and win a warâ€”all outâ€”and not with half-an-eye on the battlefronts abroad and the other eye-and-a-half on personal, selfish, or political interests here at home.\n",
      "\n",
      "Therefore, in order to concentrate all our energies and resources on winning the war, and to maintain a fair and stable economy at home, I recommend that the Congress adopt:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "This Nation in the past two years has become an active partner in the world's greatest war against human slavery. We have joined with like-minded people in order to defend ourselves in a world that has been gravely threatened with gangster rule. But I do not think that any of us Americans can be content with mere survival. Sacrifices that we and our allies are making impose upon us all a sacred obligation to see to it that out of this war we and our children will gain something better than mere survival. We are united in determination that this war shall not be followed by another interim which leads to new disaster- that we shall not repeat the tragic errors of ostrich isolationismâ€”that we shall not repeat the excesses of the wild twenties when this Nation went for a joy ride on a roller coaster which ended in a tragic crash. When Mr. Hull went to Moscow in October, and when I went to Cairo and Teheran in November, we knew that we were in agreement with our allies in our common determination to fight and win this war. But there were many vital questions concerning the future peace, and they were discussed in an atmosphere of complete candor and harmony. In the last war such discussions, such meetings, did not even begin until the shooting had stopped and the delegates began to assemble at the peace table. There had been no previous opportunities for man-to-man discussions which lead to meetings of minds. The result was a peace which was not a peace. That was a mistake which we are not repeating in this war.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "It will give our people at home the assurance that they are standing four-square behind our soldiers and sailors. And it will give our enemies demoralizing assurance that we mean business -that we, 130,000,000 Americans, are on the march to Rome, Berlin, and Tokyo.\n",
      "\n",
      "I hope that the Congress will recognize that, although this is a political year, national service is an issue which transcends politics. Great power must be used for great purposes.\n",
      "\n",
      "As to the machinery for this measure, the Congress itself should determine its natureâ€”but it should be wholly nonpartisan in its make-up.\n",
      "\n",
      "Our armed forces are valiantly fulfilling their responsibilities to our country and our people. Now the Congress faces the responsibility for taking those measures which are essential to national security in this the most decisive phase of the Nation's greatest war.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "documents = TextLoader(\"../session2/some_data/FDR_State_of_Union_1944.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    "\n",
    "docs = retriever.invoke(\"What did the president say about germany\")\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473c553",
   "metadata": {
    "id": "3473c553"
   },
   "source": [
    "## Adding contextual compression with an `LLMChainExtractor`\n",
    "Now let's wrap our base retriever with a `ContextualCompressionRetriever`. \n",
    "\n",
    "We'll add an `LLMChainExtractor`, a Document compressor that uses an LLM chain to extract the relevant parts of documents.\n",
    "\n",
    "This will iterate over the initially returned documents and extract from each only the content that is relevant to the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83e3c63-bcde-43e9-998e-35bf2ebef49b",
   "metadata": {
    "id": "d83e3c63-bcde-43e9-998e-35bf2ebef49b",
    "outputId": "ce802a97-2f3d-4eb8-8091-686bb19f1efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "- The foreign policy that we have been followingâ€”the policy that guided us at Moscow, Cairo, and Teheranâ€”is based on the common sense principle which was best expressed by Benjamin Franklin on July 4, 1776: \"We must all hang together, or assuredly we shall all hang separately.\"\n",
      "- I have often said that there are no two fronts for America in this war. There is only one front. There is one line of unity which extends from the hearts of the people at home to the men of our attacking forces in our farthest outposts.\n",
      "- When we speak of our total effort, we speak of the factory and the field, and the mine as well as of the battleground -- we speak of the soldier and the civilian, the citizen and his Government.\n",
      "- Each and every one of us has a solemn obligation under God to serve this Nation in its most critical hourâ€”to keep this Nation great -- to make this Nation greater in a better world.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The President called for \"force to the utmost,\" and his call was heeded. And in November, only three months later, Germany surrendered.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "- \"When Mr. Hull went to Moscow in October, and when I went to Cairo and Teheran in November, we knew that we were in agreement with our allies in our common determination to fight and win this war.\"\n",
      "- \"But there were many vital questions concerning the future peace, and they were discussed in an atmosphere of complete candor and harmony.\"\n",
      "- \"In the last war such discussions, such meetings, did not even begin until the shooting had stopped and the delegates began to assemble at the peace table.\"\n",
      "- \"There had been no previous opportunities for man-to-man discussions which lead to meetings of minds.\"\n",
      "- \"The result was a peace which was not a peace.\"\n",
      "- \"That was a mistake which we are not repeating in this war.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "The president said that national service is an issue that transcends politics and that the Congress should determine the nature of the machinery for this measure. He also mentioned that the Congress faces the responsibility for taking measures essential to national security during the most decisive phase of the nation's greatest war.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, \n",
    "    base_retriever=retriever                          # retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What did the president say about germany\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97cd9b",
   "metadata": {
    "id": "8a97cd9b"
   },
   "source": [
    "## More built-in compressors: filters\n",
    "### `LLMChainFilter`\n",
    "The `LLMChainFilter` is a Filter that drops documents that aren’t relevant to the query.\n",
    "\n",
    "This slightly simpler but more robust compressor uses an LLM chain to decide which of the initially retrieved documents to filter out and which ones to return, without manipulating the document contents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b13654-01d9-4006-9550-5f3e77cb4f23",
   "metadata": {
    "id": "39b13654-01d9-4006-9550-5f3e77cb4f23",
    "outputId": "f03d0566-7ec1-4357-a796-4011705a6feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Let us remember the lessons of 1918. In the summer of that year the tide turned in favor of the allies. But this Government did not relax. In fact, our national effort was stepped up. In August, 1918, the draft age limits were broadened from 21-31 to 18-45. The President called for \"force to the utmost,\" and his call was heeded. And in November, only three months later, Germany surrendered.\n",
      "\n",
      "That is the way to fight and win a warâ€”all outâ€”and not with half-an-eye on the battlefronts abroad and the other eye-and-a-half on personal, selfish, or political interests here at home.\n",
      "\n",
      "Therefore, in order to concentrate all our energies and resources on winning the war, and to maintain a fair and stable economy at home, I recommend that the Congress adopt:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "It will give our people at home the assurance that they are standing four-square behind our soldiers and sailors. And it will give our enemies demoralizing assurance that we mean business -that we, 130,000,000 Americans, are on the march to Rome, Berlin, and Tokyo.\n",
      "\n",
      "I hope that the Congress will recognize that, although this is a political year, national service is an issue which transcends politics. Great power must be used for great purposes.\n",
      "\n",
      "As to the machinery for this measure, the Congress itself should determine its natureâ€”but it should be wholly nonpartisan in its make-up.\n",
      "\n",
      "Our armed forces are valiantly fulfilling their responsibilities to our country and our people. Now the Congress faces the responsibility for taking those measures which are essential to national security in this the most decisive phase of the Nation's greatest war.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainFilter\n",
    "\n",
    "_filter = LLMChainFilter.from_llm(llm)     # The language model to use for filtering\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=_filter, \n",
    "    base_retriever=retriever                       # retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What did the president say about germany?\"\n",
    ")\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14002ec8-7ee5-4f91-9315-dd21c3808776",
   "metadata": {
    "id": "14002ec8-7ee5-4f91-9315-dd21c3808776"
   },
   "source": [
    "### `LLMListwiseRerank`\n",
    "\n",
    "[LLMListwiseRerank](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html) uses [zero-shot listwise document reranking](https://arxiv.org/pdf/2305.02156) and functions similarly to `LLMChainFilter` as a robust but more expensive option. It is recommended to use a more powerful LLM.\n",
    "\n",
    "Note that `LLMListwiseRerank` requires a model with the [with_structured_output](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI.with_structured_output) method implemented.\n",
    "\n",
    "The `LLMListwiseRerank` approach is based on the mathematical concept of permutation optimization. If we have $n$ documents, there are $n!$ possible orderings. The LLM attempts to find the optimal permutation $\\pi^*$ that maximizes relevance:\n",
    "\n",
    "$$\n",
    "\\pi^* = \\arg\\max_{\\pi \\in \\Pi_n} \\text{Relevance}(\\pi, q)\n",
    "$$\n",
    "\n",
    "Where $\\Pi_n$ is the set of all possible permutations of $n$ documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab9ee9f-917e-4d6f-9344-eb7f01533228",
   "metadata": {
    "id": "4ab9ee9f-917e-4d6f-9344-eb7f01533228",
    "outputId": "9399207d-5c9a-4e56-da7d-c2b744379f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Let us remember the lessons of 1918. In the summer of that year the tide turned in favor of the allies. But this Government did not relax. In fact, our national effort was stepped up. In August, 1918, the draft age limits were broadened from 21-31 to 18-45. The President called for \"force to the utmost,\" and his call was heeded. And in November, only three months later, Germany surrendered.\n",
      "\n",
      "That is the way to fight and win a warâ€”all outâ€”and not with half-an-eye on the battlefronts abroad and the other eye-and-a-half on personal, selfish, or political interests here at home.\n",
      "\n",
      "Therefore, in order to concentrate all our energies and resources on winning the war, and to maintain a fair and stable economy at home, I recommend that the Congress adopt:\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import LLMListwiseRerank\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "_filter = LLMListwiseRerank.from_llm(llm, top_n=1)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=_filter, \n",
    "    base_retriever=retriever\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What did the president say about germany\"\n",
    ")\n",
    "\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194da42",
   "metadata": {
    "id": "7194da42"
   },
   "source": [
    "### `EmbeddingsFilter` or `Threshold-Based Filtering`\n",
    "\n",
    "Making an extra LLM call over each retrieved document is expensive and slow. \n",
    "\n",
    "The `EmbeddingsFilter` provides a cheaper and faster option by embedding the documents and query and only returning those documents which have sufficiently similar embeddings to the query.\n",
    "\n",
    "For the EmbeddingsFilter used in the notebook, the mathematical operation is:\n",
    "$$\n",
    "\\text{Keep document } d_i \\text{ if } \\text{similarity}(q, d_i) \\geq \\theta\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $q$ is the query embedding  \n",
    "- $d_i$ is the document embedding  \n",
    "- $\\theta$ is the similarity threshold (0.76 in the example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8d9486-db9a-4e24-aa11-ae40f34cc908",
   "metadata": {
    "id": "ee8d9486-db9a-4e24-aa11-ae40f34cc908",
    "outputId": "2a90cb71-e424-47a5-88e0-f09ba32a0139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "Let us remember the lessons of 1918. In the summer of that year the tide turned in favor of the allies. But this Government did not relax. In fact, our national effort was stepped up. In August, 1918, the draft age limits were broadened from 21-31 to 18-45. The President called for \"force to the utmost,\" and his call was heeded. And in November, only three months later, Germany surrendered.\n",
      "\n",
      "That is the way to fight and win a warâ€”all outâ€”and not with half-an-eye on the battlefronts abroad and the other eye-and-a-half on personal, selfish, or political interests here at home.\n",
      "\n",
      "Therefore, in order to concentrate all our energies and resources on winning the war, and to maintain a fair and stable economy at home, I recommend that the Congress adopt:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The foreign policy that we have been followingâ€”the policy that guided us at Moscow, Cairo, and Teheranâ€”is based on the common sense principle which was best expressed by Benjamin Franklin on July 4, 1776: \"We must all hang together, or assuredly we shall all hang separately.\"\n",
      "\n",
      "I have often said that there are no two fronts for America in this war. There is only one front. There is one line of unity which extends from the hearts of the people at home to the men of our attacking forces in our farthest outposts. When we speak of our total effort, we speak of the factory and the field, and the mine as well as of the battleground -- we speak of the soldier and the civilian, the citizen and his Government.\n",
      "\n",
      "Each and every one of us has a solemn obligation under God to serve this Nation in its most critical hourâ€”to keep this Nation great -- to make this Nation greater in a better world.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "This Nation in the past two years has become an active partner in the world's greatest war against human slavery. We have joined with like-minded people in order to defend ourselves in a world that has been gravely threatened with gangster rule. But I do not think that any of us Americans can be content with mere survival. Sacrifices that we and our allies are making impose upon us all a sacred obligation to see to it that out of this war we and our children will gain something better than mere survival. We are united in determination that this war shall not be followed by another interim which leads to new disaster- that we shall not repeat the tragic errors of ostrich isolationismâ€”that we shall not repeat the excesses of the wild twenties when this Nation went for a joy ride on a roller coaster which ended in a tragic crash. When Mr. Hull went to Moscow in October, and when I went to Cairo and Teheran in November, we knew that we were in agreement with our allies in our common determination to fight and win this war. But there were many vital questions concerning the future peace, and they were discussed in an atmosphere of complete candor and harmony. In the last war such discussions, such meetings, did not even begin until the shooting had stopped and the delegates began to assemble at the peace table. There had been no previous opportunities for man-to-man discussions which lead to meetings of minds. The result was a peace which was not a peace. That was a mistake which we are not repeating in this war.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "It will give our people at home the assurance that they are standing four-square behind our soldiers and sailors. And it will give our enemies demoralizing assurance that we mean business -that we, 130,000,000 Americans, are on the march to Rome, Berlin, and Tokyo.\n",
      "\n",
      "I hope that the Congress will recognize that, although this is a political year, national service is an issue which transcends politics. Great power must be used for great purposes.\n",
      "\n",
      "As to the machinery for this measure, the Congress itself should determine its natureâ€”but it should be wholly nonpartisan in its make-up.\n",
      "\n",
      "Our armed forces are valiantly fulfilling their responsibilities to our country and our people. Now the Congress faces the responsibility for taking those measures which are essential to national security in this the most decisive phase of the Nation's greatest war.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "embeddings_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=embeddings_filter, \n",
    "    base_retriever=retriever                         # retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What did the president say about germany\"\n",
    ")\n",
    "\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074462b",
   "metadata": {
    "id": "2074462b"
   },
   "source": [
    "## Stringing compressors and document transformers together\n",
    "Using the `DocumentCompressorPipeline` we can also easily combine multiple compressors in sequence. Along with compressors we can add `BaseDocumentTransformer`s to our pipeline, which don't perform any contextual compression but simply perform some transformation on a set of documents. For example `TextSplitter`s can be used as document transformers to split documents into smaller pieces, and the `EmbeddingsRedundantFilter` can be used to filter out redundant documents based on embedding similarity between documents.\n",
    "\n",
    "Below we create a compressor pipeline by first splitting our docs into smaller chunks, then removing redundant documents, and then filtering based on relevance to the query.\n",
    "\n",
    "\n",
    "### Redundancy Elimination\n",
    "The ```EmbeddingsRedundantFilter``` uses a similar principle but compares documents to each other:\n",
    "The filter uses a greedy algorithm to identify redundant documents:\n",
    "\n",
    "1. Initialize an empty set $R$ of documents to retain\n",
    "2. For each document $d_i$ in the original set:\n",
    "    \n",
    "    - Check if $d_i$ is too similar to any document already in $R$:\n",
    "       - $\\exists d_j \\in R \\text{ such that } S_{ij} \\geq \\theta $\n",
    "       -  If no such $d_j$ exists, add $d_i$ to $R$\n",
    "  \n",
    "This can be expressed mathematically as:\n",
    "$$R=\\{ d_j \\in D : \\forall d_j \\in R \\text{ added before } d_i,S_{ij} < \\theta \\}$$\n",
    "\n",
    "Where:\n",
    "- $S_{ij} = \\text{similarity}(d_i, d_j)$\n",
    "- $D$ is the set of documents\n",
    "- $d_i,d_j$ is document embeddings\n",
    "- $\\theta$ is the redundancy (similarity) threshold (typically between 0.8 and 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617a1756",
   "metadata": {
    "id": "617a1756"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=0, separator=\". \")\n",
    "\n",
    "redundant_filter = EmbeddingsRedundantFilter(embeddings=embeddings, similarity_threshold=0.83)\n",
    "\n",
    "relevant_filter = EmbeddingsFilter(embeddings=embeddings, similarity_threshold=0.76)\n",
    "\n",
    "pipeline_compressor = DocumentCompressorPipeline(\n",
    "    transformers=[splitter, \n",
    "                  redundant_filter, \n",
    "                  relevant_filter\n",
    "                 ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b9c1db-7ac2-4257-935a-b107da50bb43",
   "metadata": {
    "id": "40b9c1db-7ac2-4257-935a-b107da50bb43",
    "outputId": "87305728-2965-4349-9649-b94df3d935ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 352, which is longer than the specified 300\n",
      "Created a chunk of size 329, which is longer than the specified 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "The President called for \"force to the utmost,\" and his call was heeded\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "There had been no previous opportunities for man-to-man discussions which lead to meetings of minds. The result was a peace which was not a peace. That was a mistake which we are not repeating in this war.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Let us remember the lessons of 1918. In the summer of that year the tide turned in favor of the allies. But this Government did not relax. In fact, our national effort was stepped up. In August, 1918, the draft age limits were broadened from 21-31 to 18-45\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=pipeline_compressor, \n",
    "    base_retriever=retriever                            # retriever = FAISS.from_documents(texts, OpenAIEmbeddings()).as_retriever()\n",
    ")\n",
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    \"What did the president say about germany?\"\n",
    ")\n",
    "\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e57153-7358-46bf-889e-a782f2fe989f",
   "metadata": {},
   "source": [
    "# Comparison of Compression Retrievers in LangChain\n",
    "\n",
    "| Retriever | Description | Use Cases | Advantages | Disadvantages | Performance Impact |\n",
    "|-----------|-------------|-----------|------------|---------------|-------------------|\n",
    "| **Standard Retriever** (baseline) | Returns documents as-is without compression | Simple retrieval tasks with short documents | • Simple implementation<br>• No additional processing overhead | • Returns irrelevant information<br>• Higher LLM costs<br>• May include irrelevant content | Lower quality for complex queries |\n",
    "| **LLMChainExtractor** | Uses an LLM to extract only relevant content from each document | • Long documents with sparse relevant information<br>• When precision is critical | • Highly precise extraction<br>• Preserves context<br>• Can reformat content for better readability | • Expensive (requires LLM call per document)<br>• Slower than non-LLM methods<br>• May miss relevant information | High quality but highest cost |\n",
    "| **LLMChainFilter** | Uses an LLM to decide which documents to keep/discard | • When you need to reduce number of documents<br>• Maintaining complete document context | • Preserves full document content<br>• Simpler and more robust than extraction<br>• Reduces number of documents | • Still requires LLM call per document<br>• Doesn't remove irrelevant content within documents | Medium quality improvement, high cost |\n",
    "| **LLMListwiseRerank** | Uses zero-shot listwise reranking to prioritize documents | • When document order matters<br>• Prioritizing best documents<br>• High-stakes applications | • Better ranking than traditional methods<br>• Can use more powerful LLMs<br>• Considers documents collectively | • Most expensive option<br>• Requires models with structured output<br>• Complex implementation | Highest quality ranking, highest cost |\n",
    "| **EmbeddingsFilter** | Filters documents based on embedding similarity to query | • Cost-sensitive applications<br>• Real-time systems<br>• First-pass filtering | • Much faster than LLM-based methods<br>• Significantly cheaper<br>• Scales well | • Less precise than LLM methods<br>• Requires quality embeddings<br>• May miss semantic connections | Good balance of quality and cost |\n",
    "| **DocumentCompressorPipeline** | Combines multiple compressors and transformers | • Complex retrieval needs<br>• Multi-stage processing<br>• Custom workflows | • Highly customizable<br>• Can optimize for multiple objectives<br>• Combines strengths of different methods | • Complex setup<br>• Requires careful tuning<br>• Performance depends on component selection | Depends on components used |\n",
    "\n",
    "## Additional Pipeline Components\n",
    "\n",
    "| Component | Function | Best Used With |\n",
    "|-----------|----------|---------------|\n",
    "| **TextSplitter** | Splits documents into smaller chunks | • Long documents<br>• Before redundancy filtering<br>• When granularity matters |\n",
    "| **EmbeddingsRedundantFilter** | Removes similar documents based on embedding similarity | • After text splitting<br>• Before relevance filtering<br>• When working with repetitive content |\n",
    "\n",
    "## Selection Guide\n",
    "\n",
    "1. **Limited Budget**: Start with EmbeddingsFilter for cost-effective filtering\n",
    "2. **Highest Quality**: Use LLMListwiseRerank with a powerful model\n",
    "3. **Balance**: Consider a pipeline with TextSplitter → EmbeddingsRedundantFilter → EmbeddingsFilter\n",
    "4. **Flexible & Custom**: Build a DocumentCompressorPipeline tailored to your specific needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78581dcb",
   "metadata": {
    "id": "78581dcb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
