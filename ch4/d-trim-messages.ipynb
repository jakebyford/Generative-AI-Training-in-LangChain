{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32318455-f41f-4339-b36a-f189aa40e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950cf207-dcad-4446-a32c-29c9d002347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample messages\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83cfdc8-4bb2-42f9-9c03-76bb639f78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trimmer\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=65,\n",
    "    strategy=\"last\",            # controls whether to start from the beginning or the end of the list\n",
    "    token_counter=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    include_system=True,        # keeps the System Messages\n",
    "    allow_partial=False,        # determines whether to cut the last messageâ€™s content to fit within the limit. \n",
    "                                # False removes the message that would send the total over the limit.\n",
    "    start_on=\"human\",           # ensures that we never remove an AIMessage without also removing a corresponding HumanMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f78776f-beac-4203-9fa2-b2ee7e64d73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}), HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}), AIMessage(content='4', additional_kwargs={}, response_metadata={}), HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}), AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}), HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}), AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Apply trimming\n",
    "trimmed = trimmer.invoke(messages)\n",
    "print(trimmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cae6ac-a0bb-424f-a1e5-5fedc7f422e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you're a good assistant\n",
      "whats 2 + 2\n",
      "4\n",
      "thanks\n",
      "no problem!\n",
      "having fun?\n",
      "yes!\n"
     ]
    }
   ],
   "source": [
    "for i in trimmed:\n",
    "    print(i.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46947233-5e02-40d5-a603-463a73e42b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
